{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential datasets:\n",
    "- Bitcoin: https://www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory#bitcoin_dataset.csv\n",
    "- Car image classifiactoin: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
    "- cancer risk classification: https://www.kaggle.com/loveall/cervical-cancer-risk-classification\n",
    "- gender classification: https://www.kaggle.com/crowdflower/twitter-user-gender-classification\n",
    "- house price prediction: https://www.kaggle.com/shree1992/housedata\n",
    "- student grade prediction(linear regression): https://www.kaggle.com/dipam7/student-grade-prediction\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project \n",
    "- Dataset: https://www.kaggle.com/PromptCloudHQ/imdb-data\n",
    "- Notes: https://www.analyticsvidhya.com/blog/2019/04/predicting-movie-genres-nlp-multi-label-classification/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description about Dataset\n",
    "\n",
    "- 1,000 most popular movies on IMDB in 10 years from 2006-2016. \n",
    "- Feature: \n",
    "    - Title, Genre, Description, Director, Actors, Year, Runtime, Rating, Votes, Revenue, Metascrore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Predicting the genre of the movie using the description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Binary Relevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# Performance metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sukhrobjongolibboev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "## GOAL: More EDA and Visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "df = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Runtime (Minutes)</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Revenue (Millions)</th>\n",
       "      <th>Metascore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>A group of intergalactic criminals are forced ...</td>\n",
       "      <td>James Gunn</td>\n",
       "      <td>Chris Pratt, Vin Diesel, Bradley Cooper, Zoe S...</td>\n",
       "      <td>2014</td>\n",
       "      <td>121</td>\n",
       "      <td>8.1</td>\n",
       "      <td>757074</td>\n",
       "      <td>333.13</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Prometheus</td>\n",
       "      <td>Adventure,Mystery,Sci-Fi</td>\n",
       "      <td>Following clues to the origin of mankind, a te...</td>\n",
       "      <td>Ridley Scott</td>\n",
       "      <td>Noomi Rapace, Logan Marshall-Green, Michael Fa...</td>\n",
       "      <td>2012</td>\n",
       "      <td>124</td>\n",
       "      <td>7.0</td>\n",
       "      <td>485820</td>\n",
       "      <td>126.46</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Split</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>Three girls are kidnapped by a man with a diag...</td>\n",
       "      <td>M. Night Shyamalan</td>\n",
       "      <td>James McAvoy, Anya Taylor-Joy, Haley Lu Richar...</td>\n",
       "      <td>2016</td>\n",
       "      <td>117</td>\n",
       "      <td>7.3</td>\n",
       "      <td>157606</td>\n",
       "      <td>138.12</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sing</td>\n",
       "      <td>Animation,Comedy,Family</td>\n",
       "      <td>In a city of humanoid animals, a hustling thea...</td>\n",
       "      <td>Christophe Lourdelet</td>\n",
       "      <td>Matthew McConaughey,Reese Witherspoon, Seth Ma...</td>\n",
       "      <td>2016</td>\n",
       "      <td>108</td>\n",
       "      <td>7.2</td>\n",
       "      <td>60545</td>\n",
       "      <td>270.32</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Suicide Squad</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>A secret government agency recruits some of th...</td>\n",
       "      <td>David Ayer</td>\n",
       "      <td>Will Smith, Jared Leto, Margot Robbie, Viola D...</td>\n",
       "      <td>2016</td>\n",
       "      <td>123</td>\n",
       "      <td>6.2</td>\n",
       "      <td>393727</td>\n",
       "      <td>325.02</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                    Title                     Genre  \\\n",
       "0     1  Guardians of the Galaxy   Action,Adventure,Sci-Fi   \n",
       "1     2               Prometheus  Adventure,Mystery,Sci-Fi   \n",
       "2     3                    Split           Horror,Thriller   \n",
       "3     4                     Sing   Animation,Comedy,Family   \n",
       "4     5            Suicide Squad  Action,Adventure,Fantasy   \n",
       "\n",
       "                                         Description              Director  \\\n",
       "0  A group of intergalactic criminals are forced ...            James Gunn   \n",
       "1  Following clues to the origin of mankind, a te...          Ridley Scott   \n",
       "2  Three girls are kidnapped by a man with a diag...    M. Night Shyamalan   \n",
       "3  In a city of humanoid animals, a hustling thea...  Christophe Lourdelet   \n",
       "4  A secret government agency recruits some of th...            David Ayer   \n",
       "\n",
       "                                              Actors  Year  Runtime (Minutes)  \\\n",
       "0  Chris Pratt, Vin Diesel, Bradley Cooper, Zoe S...  2014                121   \n",
       "1  Noomi Rapace, Logan Marshall-Green, Michael Fa...  2012                124   \n",
       "2  James McAvoy, Anya Taylor-Joy, Haley Lu Richar...  2016                117   \n",
       "3  Matthew McConaughey,Reese Witherspoon, Seth Ma...  2016                108   \n",
       "4  Will Smith, Jared Leto, Margot Robbie, Viola D...  2016                123   \n",
       "\n",
       "   Rating   Votes  Revenue (Millions)  Metascore  \n",
       "0     8.1  757074              333.13       76.0  \n",
       "1     7.0  485820              126.46       65.0  \n",
       "2     7.3  157606              138.12       62.0  \n",
       "3     7.2   60545              270.32       59.0  \n",
       "4     6.2  393727              325.02       40.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of words from a description: ['A', 'group', 'of', 'intergalactic', 'criminals', 'are', 'forced', 'to', 'work', 'together', 'to', 'stop', 'a', 'fanatical', 'warrior', 'from', 'taking', 'control', 'of', 'the', 'universe.']\n",
      " Word count:21\n"
     ]
    }
   ],
   "source": [
    "# looking at the length of the 1st description to get a picture how long a descriotion can be\n",
    "word_count = (df[\"Description\"].values[0]).split(\" \")\n",
    "print(\"list of words from a description: {}\\n Word count:{}\".format(word_count, len(word_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [word for word in text.split() if not word in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "df['Description'] = df['Description'].apply(lambda x: remove_stopwords(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "1. Spliting input and target (input is descriptoin, movie genre would be the output)\n",
    "2. One-hot encoding \n",
    "3. multi-label classification\n",
    "    - Since movies are not one-dimensional. One movie can span several genres. Now THAT is a challenge I love to embrace as a data scientist. I extracted a bunch of movie plot summaries and got down to work using this concept of multi-label classification. And the results, even using a simple model, are truly impressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(df[[\"Description\", \"Genre\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting Old Genre Data with New Genres Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = list()\n",
    "\n",
    "for item in dataset[\"Genre\"]:\n",
    "    genres.append(item.split(\",\"))\n",
    "\n",
    "dataset[\"Genre\"] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group intergalactic criminals forced work toge...</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>following clues origin mankind, team finds str...</td>\n",
       "      <td>[Adventure, Mystery, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three girls kidnapped man diagnosed 23 distinc...</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0  group intergalactic criminals forced work toge...   \n",
       "1  following clues origin mankind, team finds str...   \n",
       "2  three girls kidnapped man diagnosed 23 distinc...   \n",
       "\n",
       "                          Genre  \n",
       "0   [Action, Adventure, Sci-Fi]  \n",
       "1  [Adventure, Mystery, Sci-Fi]  \n",
       "2            [Horror, Thriller]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mlb = MultiLabelBinarizer()\n",
    "data_mlb.fit(dataset['Genre'])\n",
    "\n",
    "# transform target variable\n",
    "target = data_mlb.transform(dataset['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[\"Description\"], \n",
    "                                                    target, \n",
    "                                                    train_size=0.75, \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_proc = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "\n",
    "X_train_TFIDF = tfidf_proc.fit_transform(X_train)\n",
    "X_test_TFIDF = tfidf_proc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL: Test multiple different classification models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression() # we're still doing classification! \n",
    "clf = OneVsRestClassifier(logreg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on train data\n",
    "clf.fit(X_train_TFIDF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for validation set\n",
    "y_pred = clf.predict(X_test_TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mlb.inverse_transform(y_pred)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24203821656050956"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate performance\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26715106, 0.36034356, 0.0592857 , ..., 0.1861672 , 0.01973362,\n",
       "        0.01365276],\n",
       "       [0.2218248 , 0.22542609, 0.05807306, ..., 0.18844254, 0.01952819,\n",
       "        0.01234747],\n",
       "       [0.4934956 , 0.33247897, 0.04794172, ..., 0.19023084, 0.01700441,\n",
       "        0.01229569],\n",
       "       ...,\n",
       "       [0.28662091, 0.18260336, 0.0447138 , ..., 0.21793851, 0.01926057,\n",
       "        0.01215912],\n",
       "       [0.26857084, 0.18485276, 0.04946756, ..., 0.21130098, 0.01909779,\n",
       "        0.01271356],\n",
       "       [0.30843659, 0.27330017, 0.05148889, ..., 0.14802742, 0.01916243,\n",
       "        0.01241234]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict probabilities\n",
    "y_pred_prob = clf.predict_proba(X_test_TFIDF)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.27 # threshold value\n",
    "y_pred_corrected = (y_pred_prob >= t).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL: Use `GridSearchCV` or Custom Hyperparameter Tuning to Boost Performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4761904761904762"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate performance\n",
    "f1_score(y_test, y_pred_corrected, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super cool code! \n",
    "\n",
    "Another way to perform **multilabel binarization** without the package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarization = dataset.Genre.str.split(',', expand=True).stack()\n",
    "mlb_data = pd.get_dummies(label_binarization, prefix='is').groupby(level=0).sum()\n",
    "dataset = dataset.join(mlb_data)\n",
    "dataset.drop(columns=[\"Genre\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary Code to Get Unique Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = set()\n",
    "\n",
    "for item in dataset[\"Genre\"]:\n",
    "    genres = item.split(\",\")\n",
    "    for genre in genres:\n",
    "        if genre not in unique_genres:\n",
    "            unique_genres.add(\"{}\".format(genre))\n",
    "\n",
    "unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in unique_genres:\n",
    "    dataset[category] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.DataFrame(data=[\"r\", \"g\", \"b\", \"b\", \"r\", \"g\", \"b\"], columns=[\"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy[\"is_red\"], dummy[\"is_green\"], dummy[\"is_blue\"] = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(dummy[\"color\"]):\n",
    "    if item == \"red\":\n",
    "        dummy[\"is_red\"].iloc[index] = 1\n",
    "    if item == \"green\":\n",
    "        dummy[\"is_green\"].iloc[index] = 1\n",
    "    if item == \"blue\":\n",
    "        dummy[\"is_blue\"].iloc[index] = 1\n",
    "        \n",
    "dummy.drop(columns=[\"color\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlb_processor = MultiLabelBinarizer()\n",
    "mlb_processor.fit(dummy[\"color\"])\n",
    "\n",
    "mlb_data = mlb_processor.transform(dummy[\"color\"])\n",
    "mlb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy[\"is_blue\"], dummy[\"is_green\"], dummy[\"is_red\"] = mlb_data[:, 0], mlb_data[:, 1], mlb_data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_processor.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL: Use WordClouds to Visualize Word Vectorization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3daa41321458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"one fish two fish red fish blue fish\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "input_str = \"one fish two fish red fish blue fish\"\n",
    "input_data = input_str.split(\" \")\n",
    "\n",
    "freqs = dict()\n",
    "\n",
    "for word in input_data:\n",
    "    if word not in freqs:\n",
    "        freqs[word] = 1\n",
    "    else:\n",
    "        freqs[word] += 1\n",
    "        \n",
    "wc = WordCloud()\n",
    "wc.generate_from_frequencies(frequencies=freqs)\n",
    "# TODO: Visualize WordCloud (WC) using MatPlotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
